\section{Berechnung von Gleichgewichten}

Zunächst werden die verschiedenen Informationszugänge, die für die Bestimmung  der Nachfrage eines Marktes zur Verfügung stehen können, beleuchtet.
Anschließend wird darauf aufbauend ein Vorgehen und die dafür nötige Theorie eingeführt, mit dem Gleichge\-wichts-Preise berechnet werden können.

\subsection{Informationszugang zum Markt}\label{section-market-access}

Bei der Berechnung eines Marktgleichgewichts müssen auf irgendeine Weise Informationen erhoben werden.
Dieser Informationszugang kann dann von Algorithmen als Schnittstelle zur Berechnung eines Gleichgewichts verwendet werden.
Die Algorithmen werden also unter der Annahme entwickelt, dass ein Orakel existiert, welches eine solche Schnittstelle zum Markt implementiert.

Da der Detailgrad der erfassbaren Informationen bei vielen Marktsituationen unterschiedlich ist, unterscheiden Leme und Wong in~\cite{PaesLeme2018} drei verschiedene Modelle:
\begin{itemize}
	\item \emph{Die Mikroskopische Sicht:} Hier kann der Wert einzelner Bündel für jeden Käufer abgefragt werden.
	Das sogenannte \emph{Wert-Orakel} bestimmt also anhand eines Käufers $i\in\first{m}$ und eines Bündels $x\in\ffirst{\fs}$ den Wert $v_i(x)$.
	\item \emph{Die Agenten-Sicht:} In diesem Modell besteht der Zugang zum Markt daraus, von jedem Käufer ein von ihm nachgefragtes Bündel bei gegebenen Preisen abfragen zu können.
	Sollten mehrere Bündel für den Käufer gleichwertig sein, so wird ein beliebiges dieser Bündel ausgegeben.
	Das \emph{Nachfrage-Orakel} berechnet also anhand eines Preisvektors $\fp\in\R^n$ und eines Käufers $i\in\first{m}$ ein Bündel $\dem_i(\fp)\in\NB(i, \fp)$.
	\item \emph{Die Makroskopische Sicht:} Hier können keine Informationen einzelner Käufer abgefragt werden, sondern nur noch auf die aggregierte Nachfrage bei gegebenen Preisen.
	Das heißt, das sogenannte \emph{Aggregierte-Nachfrage-Orakel} liefert bei Eingabe eines Preisvektors $\fp\in\R^n$ einen Nachfrage-Vektor $\dem(\fp)\in\Z_{\geq0}^n$, für den nachgefragte Bündel $x^{(i)} \in \NB(i,\fp)$ mit $\dem(p)=\sum_{i\in\first{m}} x^{(i)}$ existieren.
\end{itemize}

Es sei erwähnt, dass man anhand eines Wert-Orakels ein Nachfrage-Orakel konstruieren kann:
Sind Preise $\fp$ sowie ein Käufer $i$ gegeben, kann für jedes Bündel $x$ der Nutzen $u_i(x; \fp)$ durch je eine Abfrage des Wert-Orakels berechnet werden und ein Bündel ausgegeben werden, welches diesen Wert maximiert.
Für eine Abfrage des Nachfrage-Orakels entstehen dann $\ffirst{\fs}$ Abfragen des Wert-Orakels.

Genauso lässt sich aus einem Nachfrage-Orakel auch ein Aggregierte-Nachfrage-Orakel gewinnen: So kann man mit $m$ Abfragen des Nachfrage-Orakels für alle $i\in\{m\}$ ein nachgefragtes Bündel erhalten, welche summiert den aggregierten Nachfrage-Vektor ergeben.

Im Folgenden wird ein Verfahren diskutiert, der das Aggregierte-Nachfrage-Modell verwendet, um Walras-Preise für allgemeine Bewertungsfunktionen zu berechnen.

\subsection{Darstellung als Lineares Optimierungsproblem}

Man betrachte die Relaxation der Bestimmung von optimalen Allokationen als lineares Programm:
\begin{align*}
	\tag{P}\label{LP}
	&\max_{z} \sum_{i\in\first{m}, x\in\ffirst{\fs}} v_i(x) \cdot z_{i, x} \\[5pt]
	\text{udN.} \quad & \sum_{x\in\ffirst{\fs}} z_{i, x} = 1 & \text{für alle $i\in\first{m}$}\\[5pt]
	& \sum_{i\in\first{m}, x\in\ffirst{\fs}} x_j \cdot z_{i,x} = s_j & \text{für alle $j\in\first{n}$} \\[5pt]
	& z_{i, x} \geq 0 &\text{für alle $i\in\first{m}, x\in\ffirst{\fs}$}
\end{align*}
Führt man für die ersten $m$ Bedingungen die Variablen $(u_i)_{i\in\first{m}}$ und für die nächsten $n$ Bedingungen die Variablen $(p_j)_{j\in\first{n}}$ ein, erhält man folgendes duale Programm:
\begin{align*}
\tag{D}\label{DP}
&\min_{\fp,\fu} \sum_{i\in\first{m}} u_i + \fp \bcdot \fs \\[5pt]
\text{udN.} \quad &  u_i \geq v_i(x) - \fp \bcdot x & \text{für alle $i\in\first{m}, x\in\ffirst{\fs}$}
\end{align*}
\begin{lemma}
	Ein Walras-Gleichgewicht existert genau dann, wenn~\eqref{LP} eine ganzzahlige Optimallösung hat.
	Ist dies der Fall, so ist die Menge der Walras-Preise gerade die Menge der Optimallösungen von~\eqref{DP} projiziert auf die $\fp$-Koordinaten.
\end{lemma}
\begin{proof}
	Zunächst bemerke man, dass die zulässigen ganzzahligen Lösungen von~\eqref{LP} gerade den gültigen Allokationen entsprechen:
	Ist $z$ ganzzahlig und zulässig, so gibt es für alle $i\in\first{m}$ wegen den ersten Bedingungen genau ein Bündel $x^{(i)}\in\ffirst{\fs}$ mit $z_{i,x^{(i)}} = 1$.
	Aus den nächsten $n$ Bedingung folgt dann die Gültigkeit der Allokation $(x^{(i)})_{i\in\first{m}}$.
	Ausgehend von einer Allokation $\fx$ setzt man $z_{i,y} = 1$, falls $y = x^{(i)}$ gilt, und $z_{i,y}=0$ sonst, um zu einer ganzzahligen Lösung von~\eqref{LP} zu gelangen.
	
	Angenommen, es existiere ein Walras-Gleichgewicht $(\fx, \fp)$.
	Transformiert man die Allokation wie oben zu $(z_{i,x})_{i,x}$ und setzt man zusätzlich $u_i = \max_{x\in\ffirst{s}} v_i(x) - \fp \bcdot x$, erhält man eine primal und eine dual zulässige Lösung mit gleichem Zielfunktionswert:
	Es gilt mit $x^{(i)}\in\NB(i, \fp)$ und der Gültigkeit von $\fx$:
	\begin{align*}
		\sum_{i\in\first{m}} u_i + \fp \bcdot \fs
		&= \sum_{i\in\first{m}} \left( \max_{x\in\ffirst{\fs}} v_i(x) - \fp \bcdot x \right) + \fp \bcdot s = \sum_{i\in\first{m}} \left( v_i(x^{(i)}) - \fp\bcdot x^{(i)} \right) + \fp \bcdot \fs \\
		&= \sum_{i\in\first{m}} v_i(x^{(i)}) = \sum_{i\in\first{m}, x\in\ffirst{\fs}} v_i(x) \cdot z_{i,x}.
	\end{align*}
	Aufgrund schwacher Dualität ist $(z_{i,x})_{i,x}$ eine Optimallösung von~\eqref{LP}.
	
	Gibt es umgekehrt eine ganzzahlige Optimallösung, so kann diese wie oben zu einer gültigen Allokation $\fx$ transformiert werden.
	Aufgrund starker Dualität gibt es auch eine Optimallösung $(\fp, \fu)$ von~\eqref{DP} mit Zielfunktionswert $\sum_{i\in\first{m}} v_i(x^{(i)})$.
	Die Optimalität von $(\fp, \fu)$ impliziert bereits $u_i = \max_{x\in\ffirst{\fs}} v_i(x) - \fp \bcdot x$ für alle $i\in\first{m}$.
	Subtrahiert man $\fp \bcdot \fs$ vom Zielfunktionswert erhält man 
	\[
	\sum_{i\in\first{m}} \left( v_i(x^{(i)}) - \fp \bcdot x^{(i)} \right) = \sum_{i\in\first{m}} \max_{x\in\ffirst{\fs}} v_i(x) - \fp \bcdot x,
	\]
	wodurch $x^{(i)}\in\NB(i, \fp)$ für alle $i\in\first{m}$ folgt.
	Daher ist $\fx$ eine Walras-Allokation induziert durch die Preise $\fp$.
	
	Der zweite Teil der Aussage folgt aus dem Beweis des ersten Teils.
\end{proof}

\begin{lemma}
	Das folgende transformierte Programm ist äquivalent zu~\eqref{DP}: \emph{
	\begin{align*}
		\tag{TD}\label{TDP}
		&\min_{\fp, u} u + \fp \bcdot \fs \\[5pt]
	\text{udN.}\quad& u \geq \sum_{i\in\first{m}} \left( v_i(x^{(i)}) - \fp \bcdot x^{(i)} \right) & \text{für alle $\fx = (x^{(i)})_{i\in\first{m}}\in\ffirst{\fs}^m$}
	\end{align*}
}
\end{lemma}
\begin{proof}
	Für eine zulässige Lösung $(\fp, \fu)$ von~\eqref{DP} ist $(\fp, u)$ mit $u\coloneqq \sum_{i\in\first{m}} u_i$ eine zulässige Lösung von~\eqref{TDP} mit gleichem Zielfunktionswert.
	Umgekehrt ist für eine zulässige Lösung $(\fp, u)$ von~\eqref{TDP} mit $u_i\coloneqq \max_{x\in\ffirst{\fs}} v_i(x) - \fp \bcdot x$ auch $(\fp, \fu)$ zulässig für~\eqref{DP} mit einem Wert von höchstens $u+\fp\bcdot \fs$, da die folgende Ungleichung erfüllt ist: \[
		\sum_{i\in\first{m}} u_i = \sum_{i\in\first{m}} \max_{x\in\ffirst{\fs}} \left( v_i(x) - \fp \bcdot x \right) = \max_{\fx\in\ffirst{\fs}^m} \sum_{i\in\first{m}} \left( v_i(x^{(i)}) - \fp \bcdot x^{(i)} \right) \leq u.
	\]
\end{proof}
\begin{bemerkung} 
	In~\cite{PaesLeme2018} wird statt der Nebenbedingung in~\eqref{TDP} die Nebenbedingung $u \geq \sum_{i\in\first{m}} v_i(x) - \fp \bcdot x$ für alle $x\in\ffirst{\fs}$ betrachtet.
	Das entsprechende Problem ist jedoch nicht äquivalent zu~\eqref{DP}:
	Betrachtet man einen Markt mit nur einem Gut mit Angebot $s=1$ und zwei Käufern, deren Bewertungsfunktionen durch $v_1(0)=v_2(0)=0$ und $v_1(1)=1$ sowie $v_2(1) = -1$ gegeben sind, haben die Probleme unterschiedliche Optimalwerte.
\end{bemerkung}

\subsection{Konvexe Darstellung und Subgradienten}

Für die Berechnung von Walras-Preisen genügt es also -- im Falle ihrer Existenz -- einen Minimierer von~\eqref{DP} zu ermitteln.
Dabei können die Variablen $(u_i)_{i\in\first{m}}$ vermieden werden, indem man zu einem konvexen Minimierungsproblem wechselt:
\begin{definition}
	Seien ein Angebot $\fs$ sowie Käufer mit Bewertungen $(v_i)_{i\in\first{m}}$ gegeben. Die \emph{Marktpotenzialfunktion} ist definiert als
	\[ f:\R^n \rightarrow \R,\quad \fp \mapsto \sum_{i\in\first{m}} \left( \max_{x\in\ffirst{\fs}} v_i(x) - \fp \bcdot x \right) + \fp \bcdot \fs. \]
\end{definition}
Die Minimierer dieser Marktpotenzialfunktion sind gerade alle Optimallösungen von~\eqref{DP} projiziert auf die $\fp$-Koordinaten.
Da das Maximum und die Summe konvexer Funktionen wieder konvex sind, ist $f$ ebenfalls konvex.

Eine Möglichkeit, konvexe Funktionen zu optimieren, bildet die sogenannte Subgradienten-Methode.
Daher wird zunächst der Begriff eines Subgradients eingeführt:
\begin{definition}[Subgradient]
	Sei $f:\R^n \rightarrow \R$ eine konvexe Funktion.
	Man nennt $g\in\R^n$ einen \emph{Subgradient von $f$ an $p\in\R^n$}, falls $f(x) \geq f(p) + g\bcdot (x - p)$ für alle $x\in\R^n$ gilt.
\end{definition}
Man bemerke, dass $\fp$ eine konvexe Funktion $f$ genau dann minimiert, wenn der Nullvektor ein Subgradient von $f$ an $\fp$ ist.

\iffalse
\begin{proposition}\label{prop-convex-lipschitz}
Sei $f: \R^n \rightarrow \R$ eine konvexe und bezüglich $\norm{\cdot}$ Lipschitz-stetige Funktion mit Lipschitz-Konstante $L$.
Dann gilt $\norm{g}\leq L$ für jeden Subgradienten $g$ von $f$ an jedem Punkt $p\in\R^n$.
\end{proposition}
\begin{proof}
Es gilt $\norm{g} = g \bcdot (g \cdot \norm{g}^{-1}) \leq  f(g \cdot \norm{g}^{-1} + p) - f(p) \leq L \cdot \norm{g}\cdot \norm{g}^{-1} = L$.
\end{proof}
\fi

Zwar ist es schwierig mit dem Aggregierte-Nachfrage-Orakel Auswertungen von $f$ selbst zu machen, jedoch lassen sich sehr wohl Subgradienten von $f$ damit ermitteln:
\begin{lemma}\label{lemma-subgradient}
	Für alle $p\in\R^n$ ist $\fs - \dem(\fp)$ ein Subgradient von der Marktpotenzialfunktion $f$ an $\fp$.
\end{lemma}
\begin{proof}
	Sei $\dem(\fp) = \sum_{i\in\first{m}} x^{(i)}$ die aggregierte Nachfrage zum Preis $\fp$.
	Da $f$ eine Summe konvexer Funktionen ist, ist nach~\cite[Theorem~1.12]{Shor1985} jede Summe von Subgradienten der einzelnen Summanden in $\fp$ ein Subgradient von $f$ in $\fp$.
	Weiter ist nach~\cite[Theorem~1.13]{Shor1985} für das Maximum konvexer Funktionen jeder Subgradient einer Funktion, die in $\fp$ das Maximum annimmt, ein Subgradient der Maximumsfunktion in $\fp$.
	Des Weiteren ist für eine differenzierbare Funktion der einzige Subgradient der Gradient der Funktion.
	
	Dies heißt, da $x^{(i)}\in \arg\max_{x\in\ffirst{\fs}} v_i(x) - \fp \bcdot x$ für alle $i\in\first{m}$ gilt, sind $-x^{(i)}$ ein Subgradient von $\fp \mapsto \max_{x\in\ffirst{\fs}} v_i(x) - \fp \bcdot x$ für alle $i\in\first{m}$ und $\fs - \dem(\fp)$ ein Subgradient von $f$ an~$\fp$.
\end{proof}

\begin{lemma}\label{lemma-prices-bounded-M}
	Existiert eine Walras-Allokation $\fx$, so sind für $M\coloneqq \max_{i\in\first{m}, x\in\ffirst{\fs}} \abs{v_i(x)}$ alle Walras-Preise in $[-2M, 2M]^n$ enthalten.
\end{lemma}
\begin{proof}
	Seien $\fp$ ein Walras-Preisvektor und $j\in\first{n}$ gegeben.
	Der Preis $p_j$ übersteigt $2M$ nicht, denn sonst würde kein Käufer $j$ nachfragen:
	Da $s_j$ positiv ist, gibt es einen Käufer $i$ mit $x^{(i)}_j > 0$, für den $x^{(i)} \in\NB(i, \fp)$ folgende Ungleichung impliziert:
	\[
	v_i(x^{(i)}) - \fp \bcdot x^{(i)} \geq v_i(x^{(i)} - e_j) - \fp \bcdot ( x^{(i)} - e_j ).
	 \]
	 Es folgt also $2M \geq v_i(x^{(i)}) - v_i(x^{(i)} - e_j) \geq p_j$.
	 Umgekehrt ist $p_j$ mindestens $-2M$, denn sonst würden alle Käufer jeweils das gesamte Angebot von $j$ nachfragen:
	 Angenommen, es gilt $p_j < -2M$, so folgt $x^{(i)}_j = s_j$ für alle $i\in\first{m}$, denn für $x^{(i)}_j < s_j$ folgt der Widerspruch
	 \[ 
	 	v_i(x^{i})  - \fp \bcdot x^{(i)} < v_i(x^{(i)}) - \fp \bcdot (x^{(i)} + e_j) - 2M \leq v_i(x^{(i)} + e_j) - \fp \bcdot (x^{(i)} + e_j).
	 \]
	 Da es mindestens zwei Käufer gibt, folgt schließlich $p_j \geq -2M$.
\end{proof}

\begin{lemma}\label{lemma-prices-bounded-S}
	Die Menge der Walras-Preise ist ein Polytop, dessen Ecken $\fp$ von der Form $p_j = a_j/b$ mit $a_j,b\in\Z$ und
	$\abs{b} \leq (n+1)!\, (mS)^n$
	für $S = \max_{j\in\first{n}} s_j$ sind.
\end{lemma}
\begin{proof}
	Ergänzt man~\eqref{TDP} um Schlupfvariablen $\fy=(y_{\fx})_{\fx\in\ffirst{\fs}}$, so erhält man Bedingungen der Form $ u + \fp \bcdot \sum_{i\in\first{m}} x^{(i)} + y_{\fx} = \sum_{i\in\first{m}} v_i(x) $ für alle $i\in\first{m}, x\in\ffirst{\fs}$.
	Seien $A$ die Matrix und $b$ der Vektor, die diese Nebenbedingungen in $A \cdot (\fp, u, \fy)^T = b$ zusammenfasst.
	
	
	Aus den Grundlagen linearer Optimierung ist bekannt, dass beschränkte Optimierungsprobleme bei nichtleerem Zulässigkeitsbereich immer optimale Ecklösungen, also optimale Basislösungen, besitzen.
	Die Regel von Cramer besagt, dass optimale Basislösungen $(\fp, u, \fy)$ die Darstellung $p_j = \det(A_B^j) / \det(A_B)$ für $j\in\first{n}\cap B$ haben, wobei $A_B$ die Basisspalten von $A$ sind und $A_B^j$ aus $A_B$ durch Ersetzen der $j$-ten Spalte mit $b_B$ entsteht.
	
	Der Zähler ist also eine ganze Zahl.
	Sind Schlupfvariablen in der Basis $B$, so kann man $\det(A_B)$ jeweils nach diesen Spalten entwickeln, da $A_B$ hier nur aus Einheitsvektoren besteht.
	Es genügt also die Determinante einer $(n+1)\times(n+1)$-Submatrix mit den Spalten von $\fp$ und $u$ zu beschränken:
 	Die Einträge der Spalten von $\fp$ sind hier zwischen 0 und $m\cdot S$, sodass mit der Leibniz-Formel $\abs{\det(A_B)} \leq (n+1)!\, (m S)^{n}$ folgt.
\end{proof}
\begin{bemerkung}
	Im Vergleich zu~\cite[Lemma~5]{PaesLeme2018} ist in der Abschätzung hier die Anzahl der Käufer $m$ enthalten.
	Die Begründung der Schranke $n!\,(nS)^n$ im Beweis von~\cite[Lemma~5]{PaesLeme2018} nutzt ebenfalls die Cramersche Regel von Basislösungen des LPs mit dem Hinweis, die zugehörige Matrix enthalte nur Koeffizienten in $\{0, 1,\dots, S\}$.
	Tatsächlich enthält sie aber Koeffizienten in $\{0, 1, \dots, mS \}$.
	Es kann $\det(A_B)$ sogar den Wert $mS$ annehmen: Dazu betrachte man den Markt mit einem Gut mit $s=1$ und zwei Käufern.
	Besteht $B$ aus den durch $\fx_1 = (0,0)$ und $\fx_2= (1,1)$ induzierten Zeilen, gilt $\det(A_B) = 1\cdot 2 - 0 \cdot 1 = 2$.
	Dies ist zwar kein Gegenbeispiel, da dies nur für Bewertungen mit $v_1(1) = v_2(1)$ eine zulässige Basislösung ist und in diesem Fall $p = \det({A_B^p}) / 2 = (v_1(1) + v_2(2)) / 2$ ganzzahlig wäre.
	Jedoch lässt es Zweifel ob der Korrektheit von~\cite[Lemma~5]{PaesLeme2018} zu.
\end{bemerkung}

Für einen Spezialfall hilft nun die Ellipsoid-Methode bei der Berechnung von Walras-Preisen.
Diese wird beispielsweise in~\cite[Abschnitt~2]{ellipsoid} diskutiert und es lässt sich folgendes Theorem daraus ableiten:

\begin{theorem}[Ellipsoid-Methode]
Seien eine konvexe Menge $K\subseteq B_r(\zero)\subseteq \R^n$ und ein Trennorakel gegeben, also ein Orakel, das für einen Punkt $\fp\in B_r(\zero)$  entweder die Meldung \glqq\,$\fp\in K$\grqq\ oder eine Halbebene $H=\{ \fp \in\R^n \mid \fa \bcdot \fp \leq b \}$ mit $K\subseteq H$ ausgibt.

Dann lässt sich mit $t$ Abfragen des Orakels entweder ein Punkt $\fp\in K$ oder eine Ellipse mit Maximalvolumen $\exp({-t / ({2n + 1}})) \cdot \vol(B_r(\zero))$, welche die Menge $K$ enthält, ermitteln.
\end{theorem}

Bei der Suche nach einem Trennorakel hilft hier natürlich das Aggregierte-Nachfrage-Orakel, mit dem sich Subgradienten der Marktpotenzialfunktion berechnen lassen.

\begin{theorem}\label{thm-compute-walras-with-ellipsoid}
	Gilt $\interior(K) \neq \emptyset$ für die Menge $K$ der Walras-Preise im $\R^n$, so kann man mit $\bigO(n\log(Mn) + n^2 \log(n m S))$ Abfragen des Aggregierte-Nachfrage-Orakels und Iterationen der Ellipsoidmethode einen Walras-Preisvektor bestimmen.
\end{theorem}
\begin{proof}
	Nach Lemma~\ref{lemma-prices-bounded-M} sind alle Walras-Preise in der Menge $[-2M, 2M]^n\subseteq B_{r}(\zero)$ mit $r = 2M\sqrt{n}$ enthalten.
	Außerdem gilt $K = \arg\min_\fp f(\fp)$ wobei $f$ die Marktpotenzialfunktion ist.
	Als Trennorakel dient hier das Aggregierte-Nachfrage-Orakel, welches mit $g \coloneqq s - \dem(\fp_0)$ für $\fp_0\in\R^n$ nach Lemma~\ref{lemma-subgradient} einen Subgradienten von $f$ an $\fp_0$ ermitteln kann.
	Ist $g = \zero$, so kann \glqq$\fp_0 \in K$\grqq\ gemeldet werden.
	Sonst gilt für die Halbebene $H\coloneqq\{ \fp\in\R^n \mid g\bcdot \fp \leq g\bcdot \fp_0 \}$ dann $g\bcdot \fp^* \leq f(\fp^*) - f(\fp_0) + g \bcdot \fp_0 \leq g \bcdot \fp_0$ für alle $\fp^*\in K$, was $K\subseteq H$ impliziert.
	
	Da $\interior(K)$ nichtleer ist, existieren Ecken $\fp_0, \dots, \fp_n$ von $K$, sodass der Simplex $S$, welcher durch diese Ecken aufgespannt wird, positives Volumen hat.
	Dieses Volumen kann mit
	\[ \vol(S) = \abs{ \frac{1}{n!} \det\left(  \begin{array}{ccccc}
		1 & 1 & \cdots & 1 \\	
		\fp_0 & \fp_1 & \cdots & \fp_n
	\end{array}  \right)}  \eqqcolon \abs{ \frac{1}{n!} \det(A) } \]
	berechnet werden.
	Nach Lemma~\ref{lemma-prices-bounded-S} kann der Nenner der Einträge eines jeden Walras-Preisvektors durch $R \coloneqq (n+1)!\ (mS)^n$ abgeschätzt werden.
	Multipliziert man jede Spalte mit seinem Nenner,
	erhält man eine ganzzahlige Matrix $\tilde{A}$ mit $\lvert \det(\tilde{A}) \rvert > 0$,
	welche die Ungleichung $\abs{ \det(A) } \geq R^{-(n+1)} \lvert \det(\tilde{A}) \rvert \geq R^{-(n+1)}$ erfüllt.
	Entsprechend gilt also $\vol(K) \geq \vol(S) \geq R^{-(n+1)} / n! \geq (nR)^{-(n+1)}$.
	
	Gibt die Ellipsoidmethode nach $t$ Iterationen eine Ellipse $E$ aus, welche die Bedingungen $\vol(E) \leq \exp(-t / ({2n + 1}))\cdot (4M \sqrt{n})^n$ und $K\subseteq E$ erfüllt, gilt mit $\vol(E) \geq \vol(K)$:
	\[ \exp(-t / ({2n + 1}))\cdot (4M\sqrt{n})^n \geq (nR)^{-(n+1)}
	~ \Leftrightarrow ~ \exp(t) \leq (4M\sqrt{n})^n \exp(2n+1) (nR)^{n+1} \]
	Insbesondere gilt also $t\in\bigO(n\log(Mn) + n\log(nR)) = \bigO(n\log(Mn) + n^2 \log(n m S))$.
	Daher ist die Ellipsoidmethode dazu gezwungen nach so vielen Iterationen einen Punkt $\fp\in K$ auszugeben.
\end{proof}

\iffalse
\todo{Zitat}
\begin{theorem}\label{thm-cutting-plane-method}
	Seien eine konvexe Menge $K\subseteq [-M,M]^n$ und ein Trennorakel gegeben, also ein Orakel, das für einen Punkt $\fp\in[-M,M]^n$ in einer Laufzeit von $T$ entweder die Meldung \glqq\,$\fp\in K$\grqq\ oder eine Halbebene $H=\{ \fp \in\R^n \mid \fa \bcdot \fp \leq b \}$ mit $K\subseteq H$ ausgibt.
	
	Dann lässt sich in $\bigO(nT\log(nM/\delta) + n^3 \log^{\bigO(1)}(nM)\log^2(nM/\delta))$ Zeit entweder ein Punkt $\fp\in K$ oder ein Polytop $P=\{ \fp\in\R^n \mid \fa_i \bcdot \fp \leq b_i, i\in\first{k} \}$ mit $k=\bigO(n)$ und den folgenden Eigenschaften ermitteln:
	\begin{itemize}
		\item Jede Bedingung $\fa_i \bcdot \fp \leq b_i$ von $P$ ist entweder von der Form $p_i \leq M$ oder $p_i\geq -M$ oder wurde vom Trennorakel erstellt, wobei $\norm{\fa_i}=1$ gilt.
		\item Das Polytop $P$ ist schmal, das heißt, es gibt einen Vektor $\fa$ mit $\norm{\fa}=1$ und 
	\[
	\max_{\fp\in P} \fa \bcdot \fp - \min_{\fp\in P} \fa \bcdot \fp = \bigO(n\delta \log(nM/\delta)).
	\]
		\item Der Algorithmus erstellt ein Zertifikat der Schmalheit, also eine Konvexkombination $t_1,\dots,t_k$ mit $t_i\geq0$ für $i\in\first{k}$ und $\sum_{i\in\first{k}}t_i = 1$, die die folgenden Schranken erfüllt:
		\[
		\norm{\, \sum_{i\in\first{k}} t_i \fa_i \, } = \bigO\left( \frac{\delta}{M} \sqrt{n} \log\left( \frac{M}{\delta} \right) \right)
		\qquad
		\text{und}
		\qquad
		\abs{\sum_{i\in\first{k}} t_i b_i} = \bigO\left(n\delta\log\left(\frac{M}{\delta}\right) \right).
		\]
	\end{itemize}
\end{theorem}
\todo{blaa}

\begin{proposition}\label{prop-trivial-bound-thm}
	Für ein Polytop, das aus dem Algorithmus von Theorem~\ref{thm-cutting-plane-method} hervorgeht, gilt für Punkte $\fp^*\in K$:
	\[
		\sum_{i\in\first{k}} t_i (b_i - \fa_i \bcdot \fp^*) \leq \bigO\left( n\delta\log\left(\frac{M}{\delta}\right) \right).
	\]
\end{proposition}
\begin{proof}
	Mit der Dreiecksungleichung, der Cauchy-Schwarzschen Ungleichung sowie den Beschränkungen aus Theorem~\ref{thm-cutting-plane-method} gilt:
	\begin{align*}
	\sum_{i\in\first{k}}  t_i (b_i - \fa_i \bcdot \fp^*)
	&= \sum_{i\in\first{k}} t_i b_i
	- \left( \sum_{i\in\first{k}} t_i \fa_i \right)\bcdot \fp^*
	\leq
	\abs{\sum_{i\in\first{k}} t_i b_i}
	+ \norm{\sum_{i\in\first{k}} t_i \fa_i} \cdot \norm{p^*}
	\\[5pt]
	&\leq \bigO\left( 
	n\delta \log\left(\frac{M}{\delta}\right)
	+ \frac{\delta}{M}\sqrt{n}\log\left( \frac{M}{\delta} \right)
	\cdot M \sqrt{n}
	\right)
	= \bigO\left(
	n\delta\log\left( \frac{M}{\delta} \right)
	\right)
	\end{align*}
\end{proof}

\begin{theorem}\label{thm-approximate-solution}
	Seien eine konvexe, $L$-Lipschitz-stetige Funktion $f:\R^n\rightarrow \R$ sowie ein Subgradienten-Orakel, welches für einen Punkt $\fp$ mit Laufzeit $T$ einen Subgradienten von $f$ in $p$ ausgibt, gegeben.
	Existiert ein Minimierer von $f$ in $[-M, M]^n$, kann ein Punkt $\bar{\fp}$ mit $f(\bar{\fp}) - \min_{\fp\in\R^n} f(p)\leq \varepsilon$ in $\bigO(n T \log(n M L / \varepsilon) + n^3 \log^{\bigO(1)} (nML) \log^2(nML/\varepsilon) )$ Zeit gefunden werden.
\end{theorem}
\begin{proof}
	Seien zunächst $M'\coloneqq n^{\bigO(1)}M$ und $K\coloneqq \arg\min_{\fp\in\R^n} f(\fp)\cap [-M', M']^n$ die konvexe, nichtleere Menge der Minimierer von $f$ in $[-M',M']^n$.
	Theorem~\ref{thm-cutting-plane-method} wird mit dem erweiterten Quader $[-M', M']^n$ und dem Subgradienten-Orakel angewandt:
	Dieses gibt für einen Punkt $\fp_0$ die Halbebene $H\coloneqq\{ \fp\in\R^n \mid g\bcdot \fp \leq g\bcdot \fp_0 \}$ aus, wobei $g$ ein Subgradient von $f$ in $\fp$ ist.
	Für alle $\fp^*\in K$ gilt dann $g\bcdot \fp^* \leq f(\fp^*) - f(\fp) + g \bcdot \fp \leq g \bcdot \fp$, was $K\subseteq H$ impliziert.
	
	Gibt der Algorithmus einen Punkt in $K$ aus, ist dieser ein Minimierer von $f$ und erfüllt die geforderte Schranke.
	Sonst erhält man ein Polytop $P= \{ \fp\in\R^n \mid \fa_i \bcdot \fp \leq b_i, i\in\first{k} \}$ mit den Eigenschaften aus Theorem~\ref{thm-cutting-plane-method}.
	
	Entstammen alle Ungleichungen des Polytops dem Orakel, so gelten $\fa_i = g_i\cdot \norm{g_i}^{-1}$ und $b_i = g_i\bcdot \fp_i \cdot \norm{g_i}^{-1}$ mit Punkten $\fp_i\in\R^n$ und Subgradienten $g_i$ von $f$ in $\fp_i$ für $i\in\first{k}$.
	Sei $\fp^*\in K$ ein Minimierer von $f$.
	Mit der gegebenen Konvexkombination $(t_i)_{i\in\first{k}}$ erhält man nun einen gesuchten Punkt durch $\bar{\fp} \coloneqq \sum_{i\in\first{k}} t_i \fp_i$:
	\begin{align*}
		f(\bar{\fp}) - f(\fp^*)
		&\leq \sum_{i\in\first{k}} t_i f(\fp_i) - f(\fp^*)
		= \sum_{i\in\first{k}} t_i (f(\fp_i) - f(\fp^*))
		\leq \sum_{i\in\first{k}} t_i g_i \bcdot (\fp_i - \fp^*) \\
		&= L\cdot \sum_{i\in\first{k}}  t_i \fa_i \bcdot (\fp_i - \fp^*)
		\leq \bigO\left(
			Ln\delta\log\left( \frac{M'}{\delta} \right)
		\right)
	\end{align*}
	Die erste Ungleichung folgt aufgrund der Konvexität; die zweite gilt nach Definition von Subgradienten.
	Die dritte gilt nach Proposition~\ref{prop-trivial-bound-thm}
	
	Man kann nun $\delta$ so klein wählen, dass $\varepsilon\leq\bigO(Ln\delta\log(M/\delta))$ gilt.
	\todo{Wie soll ich damit die Laufzeit erklären? Also auf was soll ich delta denn tatsächlich setzen damit das gewünschte raus kommt? Auf das s.u.?!}
	
	Sei nun $B$, die Menge der Indizes der Bedingungen des Polytops $P$ von der Form $p_i \leq M'$ oder $-p_i \leq M'$, nicht leer.
	Für alle $i\in B$ gilt dann wegen $\fa_i\in\{e_i, -e_i \}$ und $b_i=M'$ bereits $b_i - \fa_i\bcdot p^* \geq M' - \abs{p^*_i} \geq M' - M = \Omega(n^{\bigO(1)}M)$.
	Proposition~\ref{prop-trivial-bound-thm} impliziert nun
\[ 
	t_i \Omega(n^{\bigO(1)} M)
	\leq t_i (b_i - \fa_i \bcdot \fp^*)
	\leq \sum_{j\in\first{k}} t_j (b_j - \fa_j \bcdot \fp^*)
	\leq \bigO\left(  n\delta\log\left( \frac{M'}{\delta}  \right) \right),
\]
	wodurch man $t_i\leq \bigO(\delta / (n^{\bigO(1)} M)  \log(M'/\delta))$ folgern kann.
	Wählt man $\delta$ sehr klein, also $\delta=\bigO(\varepsilon/(Ln^{\bigO(1)} M^{\bigO(1)} ))$, \todo{ erhält man $\sum_{i\in B} t_i \leq \bigO(\varepsilon/(n^{\bigO(1)}) M^{\bigO(1)}) \leq 1/2$ und $\sum_{i\in\first{k}} t_i(b_i - \fa_i \bcdot \fp^*) \leq \bigO(\varepsilon / (Ln^{\bigO(1)}M^{\bigO(1)})) $  (?????)}.
	Entfernt man nun die Skalare aus $B$ und skaliert man die restliche Konvexkombination zu $t_i'\coloneqq t_i / (1 - \sum_{j\in B} t_j)$ für alle $i\in\first{k}\setminus B$, ergibt sich:
	\begin{align*}
		\sum_{i\in \first{k}\setminus B} t_i'(b_i - \fa_i \bcdot \fp^*)
		&\leq 2 \left( 1-\sum_{i\in B}t_i  \right) \left( \sum_{i\in \first{k}\setminus B} t_i' (b_i - \fa_i \bcdot \fp^*) \right)
		= 2 \sum_{i\in \first{k}\setminus B} t_i (b_i - \fa_i \bcdot \fp^*)\\
		&\leq 2\sum_{i\in\first{k}} t_i(b_i - \fa_i\bcdot \fp^*)
		\leq \bigO\left(\frac{\varepsilon}{Ln^{\bigO(1)}M^{\bigO(1)}}\right)
		\todo{\leq \frac{\varepsilon}{L}}
	\end{align*}
	Wendet man nun das Argument für den Fall, in dem ausschließlich Orakel-Bedingungen vorkommen, mit der obigen Ungleichung statt Proposition~\ref{prop-trivial-bound-thm} an, so erhält man das gewünschte Ergebnis.
	\todo{Aber in welcher Laufzeit?}
\end{proof}

Diese Methode der Optimierung konvexer Funktionen wird nun genutzt, um das vorgestellte Probleme sogar exakt zu lösen.
\todo{bla bei konvexen allgemein gehts nicht, bei linearen schon}
Dazu werden zunächst Störungen bei der Zielfunktion zugelassen, anschließend eine angenäherte Lösung mittels Theorem~\ref{thm-approximate-solution} berechnet und schließlich durch gezieltes Runden eine exakte Lösung ermittelt.

Die Störung erfolgt, indem das transformierte duale Problem~\eqref{TDP} durch einen Störungs\-vektor $\fr\in\R^n$ ergänzt wird:
\begin{align*}
	\label{PDP}\tag{PD}
	&\min_{\fp, u} u + \fp \bcdot (\fs + \fr)\\[5pt]
	\text{udN.}\quad
	& u\geq \sum_{i\in\first{m}} \left( v_i(x^{(i)}) -\fp \bcdot x^{(i)} \right)
	& \text{für alle $\fx=(x^{(i)})_{i\in\first{m}}\in\ffirst{\fs}^m$}
\end{align*}

\begin{lemma}
	Gilt \todo{ $r_i < (nS)^{-(2n+1)}$ } für alle $i\in\first{n}$, so ist eine optimale Lösung von~\eqref{PDP} auch optimal für~\eqref{TDP}.
\end{lemma}
\begin{proof}
	Es sei $\mathcal{C}$ die Menge der Ecken des Zulässigkeitsbereichs von~\eqref{TDP}.
	Die Einträge solcher Ecken sind nach Lemma~\ref{lemma-prices-bounded-S} von der Form $a_j / b$ mit $a,b\in\Z$ und \[
	\abs{b} \leq (n+1)!\, (mS)^n \leq ((n+1)mS)^{n+1} \eqqcolon q.
	\]
	Da die lineare Zielfunktion von~\eqref{TDP} nur ganzzahlige Koeffizienten hat, ist auch der Zielfunktionswert ein Bruch, dessen Nenner durch $q$ beschränkt ist.
	Der Zielfunktionswert $a/b$ einer optimalen Ecklösung unterscheidet sich also vom Wert $a'/b'$ einer nicht-optimalen Ecklösung mindestens um $\abs{a / b - a' / b'} = \abs{ (ab' - a'b) / (b b') } \geq 1/q^2$.
	
	\todo{Da $r_i < (nS^{-2n-2})$ für alle $i\in\first{n}$ gilt, beläuft sich die durch die Störung verursachte Differenz des Zielfunktionswerts auf weniger als $nS\cdot (nS)^{-2n-2} = (nS)^{-2n}$.
	Daher ist eine Optimalecklösung von~\eqref{PDP} immer auch eine Optimalecklösung von~\eqref{TDP}.
	
	VORSCHLAG:
	
	Da $r_i < (2qM)^{-1}$ für alle $i\in\first{n}$ gilt, beläuft sich die durch die Störung verursachte Differenz des Zielfunktionswerts nach Lemma~\ref{lemma-prices-bounded-M} auf weniger als $n \cdot (2M)\cdot (2qM)^{-1} \leq n/q \leq 1/q^2$.
	Daher ist eine Optimalecklösung von~\eqref{PDP} immer auch eine Optimalecklösung von~\eqref{TDP}.
}
\end{proof}

\fi